# -*- coding: utf-8 -*-
"""ECT_HW6_104403553_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eapxxJ3DvYj0YbGsQgUJYzj6hNzDGZCb

## import necessary libraries
"""

import pandas as pd
import numpy as np
from sklearn import preprocessing, metrics
from sklearn.model_selection import train_test_split

"""## 讀檔 Breast Cancer.csv"""

df = pd.read_csv('BreastCancer.csv')
df.info()

"""## (a)切分 feature= radius_mean, area_mean label = diagnosis"""

x = df.loc[:,["radius_mean","area_mean"]]
y = df.loc[:,['diagnosis']]

"""##(b)切分  資料及訓練集"""

train_X, test_X, train_y, test_y = train_test_split(x, y, test_size = 0.34, random_state = 5)

"""## (c)做個knn吧"""

from sklearn.neighbors import KNeighborsClassifier as KNN

clf = KNN(n_neighbors = 6).fit(train_X ,train_y)

"""## (d)算個精準度 0.91好像還不錯欸"""

predicted_results = clf.predict(test_X)
accuracy_test = metrics.accuracy_score(predicted_results, test_y)
print('accuracy: ',accuracy_test)

"""## (e)用matplotlib 
x = radius_mean<br>
y = are_mean<br>
 c= label = y['diagnosis']
"""

import matplotlib
import matplotlib.pyplot as plt

matplotlib.rc('axes',edgecolor='w')
title_1 = plt.title('KNN without removing outliers')
plt.setp(title_1)
#title_1.setcolor("white")
#plt.tick_params(axis='x', colors='white')
#plt.tick_params(axis='y', colors='white')
#plt.ylabel.label.set_color("red")
label_x = plt.xlabel("radius_mean")
#label_x.set_color("white")

label_y = plt.ylabel("area_mean")
#label_y.set_color("white")

plt.scatter(x['radius_mean'],x['area_mean'], c = y['diagnosis'], alpha = 0.5, edgecolor= 'w')

#plt.xlabel('radius_mean')
#plt.ylabel('area_mean')
plt.show()

"""## (f) 做一下kmeans"""

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=2)

"""## (g) 這個時候來點fit_predict，又fit又predict，找出cluster"""

kmeans_cluster = kmeans.fit_predict(x)

"""## (h)matplotlib再度出動來畫畫圖，這次來看看cluster的分類畫得如何"""

import matplotlib
import matplotlib.pyplot as plt

title_2 = plt.title('K-means without removing outliers')
plt.setp(title_2)
#matplotlib.rc('axes',edgecolor='w')
#plt.tick_params(axis='x', colors='white')
#plt.tick_params(axis='y', colors='white')
#plt.ylabel.label.set_color("red")
label_x_2 = plt.xlabel("radius_mean")
#label_x_2.set_color("white")

label_y_2 = plt.ylabel("area_mean")
#label_y_2.set_color("white")

plt.scatter(x['radius_mean'],x['area_mean'], c = kmeans_cluster, alpha = 0.5, edgecolor= 'w')


plt.show()

"""## (i)移除比2000大的，就是留下比2000小的意思啦"""

# ro = remove outlier
df_ro =  df[(df['area_mean']<2000)]

"""## (h-a) 就是重做一遍a-e的a 重切feature and labels"""

x_ros = df_ro.loc[:,['radius_mean','area_mean']]
y_ros = df_ro.loc[:,['diagnosis']]

"""## (h-b) 再做一次train test切"""

train_X_ros, test_X_ros, train_y_ros, test_y_ros = train_test_split(x_ros, y_ros, test_size = 0.34, random_state = 5)

"""## (h-c) 在一次knn喔 這次移除離群值版"""

from sklearn.neighbors import KNeighborsClassifier as KNN

clf_ros = KNN(n_neighbors = 6).fit(train_X_ros ,train_y_ros)

"""## (h-d) 結果一掉之後accuracy居然有掉落
somehow覺得我可能有做錯
"""

predicted_results = clf.predict(test_X_ros)
accuracy_test = metrics.accuracy_score(predicted_results, test_y_ros)
print('accuracy: ',accuracy_test)

"""## (h-e) 這個圖再次上演，我覺得分類做的沒有之前好"""

title_1 = plt.title('KNN with outlier removal')
plt.setp(title_1)

#plt.tick_params(axis='x', colors='white')
#plt.tick_params(axis='y', colors='white')
#plt.ylabel.label.set_color("red")
label_x_2 = plt.xlabel("radius_mean")
#label_x_2.set_color("white")

label_y_2 = plt.ylabel("area_mean")
#label_y_2.set_color("white")

plt.scatter(x_ros['radius_mean'],x_ros['area_mean'], c = y_ros['diagnosis'], alpha = 0.5, edgecolor= 'w')


plt.show()

